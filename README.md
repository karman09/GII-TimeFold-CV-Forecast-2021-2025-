ğŸ§­ 1. Proje Ã–zeti

Bu proje, yÄ±llÄ±k veriler Ã¼zerinde gelecek yÄ±llarÄ± tahmin etmek iÃ§in tasarlanmÄ±ÅŸ, tamamen sÄ±zÄ±ntÄ±sÄ±z, gerÃ§ekÃ§i, zaman boyutuna duyarlÄ± bir makine Ã¶ÄŸrenimi pipelineâ€™Ä±dÄ±r.

Pipeline; veri temizleme, Ã¶zellik seÃ§imi, Ã§oklu model eÄŸitimi ve zaman tabanlÄ± Ã§apraz doÄŸrulama adÄ±mlarÄ±nÄ± eksiksiz uygulayarak 2025 tahmini Ã¼retir.

KullanÄ±lan ana bileÅŸenler:

ğŸ›¡ Zero-Leakage Training

â³ Time-Based Fold Cross-Validation (Year â†’ Year+1)

ğŸ” Modified Z-Score Outlier Detection

ğŸ©º Median + KNN Imputation (train-only)

ğŸ“ Train-Only Standardization

ğŸ§¬ LASSO Feature Selection

ğŸ” Iterative VIF Filtering (Multicollinearity)

ğŸ¤– ML Modelleri: XGBoost, LightGBM, RandomForest, AdaBoost

ğŸ¯ Son yÄ±l (2025) iÃ§in final tahmini

ğŸ—‚ï¸ 2. Pipeline Mimarisi

Notebook'un uyguladÄ±ÄŸÄ± adÄ±mlar aÅŸaÄŸÄ±daki gibi Ã¶zetlenmiÅŸtir.

ğŸ” 2.1 Outlier Detection â€” Modified Z-Score

YalnÄ±zca train yÄ±llarÄ±nda hesaplanÄ±r

|Z| > 3.5 olan gÃ¶zlemler â†’ NaN

Median & MAD â†’ leakageâ€™sÄ±z hesaplama

âœ” Test set'e dokunmaz
âœ” Gelecek yÄ±llarÄ±n bilgisi kullanÄ±lmaz

ğŸ©º 2.2 Median Imputation (Only Outlier NaNs)

Outlier â†’ NaN olan deÄŸerleri doldurur

Train median â†’ testâ€™e uygulanÄ±r

Ã‡ifte imputasyon yoktur

ğŸ“ 2.3 Scaling (StandardScaler â€” Train Only)
scaler.fit(train)
scaler.transform(train)
scaler.transform(test)


âœ” Parametreler geleceÄŸi gÃ¶rmez
âœ” Zaman sÄ±rasÄ± korunur

ğŸ§® 2.4 KNN Imputation â€” Scaled Domain

Notebookâ€™taki prensip:

scale â†’ KNN â†’ inverse scale

Train scaled â†’ KNN ile doldurulur

Test scaled â†’ train-fitted KNN ile doldurulur

Sonra inverse-scale edilir

ğŸ§¬ 2.5 LASSO Feature Selection (LassoCV)

CV ile optimum alpha

SÄ±fÄ±r olmayan katsayÄ±lÄ± deÄŸiÅŸkenler

SeÃ§ilmiÅŸ deÄŸiÅŸken tablosu

TÃ¼rkÃ§e Ã§eviri eÅŸlemeleri

ğŸ” 2.6 Multicollinearity Control â€” VIF Filtering

VIF > 10 olan deÄŸiÅŸkenler Ã§Ä±karÄ±lÄ±r

DÃ¶ngÃ¼ VIF < 10 olana kadar devam eder

SonuÃ§: daha stabil, daha anlamlÄ± Ã¶zellik seti

ğŸŒ 2.7 TÃ¼rkÃ§e DeÄŸiÅŸken Ä°simleri

translation_map iÃ§inden otomatik Ã§eviri

Final Excel raporlarÄ± TÃ¼rkÃ§e isimlerle oluÅŸturulur

Rapor okunabilirliÄŸi artÄ±rÄ±lÄ±r

ğŸ¤– 3. Model EÄŸitimi

Notebook dÃ¶rt farklÄ± regresyon modeli ile eÄŸitim yapar:

âš¡ XGBoost Regressor

Gradient Boosting tabanlÄ±

HÄ±zlÄ± + yÃ¼ksek doÄŸruluk

Non-linear iliÅŸkileri iyi yakalar

ğŸ’¡ LightGBM Regressor

Memory efficient

BÃ¼yÃ¼k veri odaklÄ±

Ã‡ok hÄ±zlÄ± eÄŸitim sÃ¼resi

ğŸŒ² RandomForest Regressor

Bagging tabanlÄ±

YÃ¼ksek kararlÄ±lÄ±k

Hyperparametre baÄŸÄ±mlÄ±lÄ±ÄŸÄ± dÃ¼ÅŸÃ¼k

ğŸ”º AdaBoost Regressor

Weak learner â†’ strong learner

DecisionTree tabanlÄ± boosting

YÃ¼ksek bias senaryolarÄ±nÄ± iyileÅŸtirir

Basit ama etkili bir boosting algoritmasÄ±

Her model iÃ§in notebook ÅŸunlarÄ± hesaplar:

Train RÂ²

Test RÂ²

RMSE

MAE

MAPE (%)

Time-Fold CV RÂ² (Mean & Std)

Model Ã§alÄ±ÅŸma sÃ¼resi

SonuÃ§lar tablo halinde raporlanÄ±r.

ğŸ§ª 4. Time-Fold Cross-Validation YapÄ±sÄ±

Her foldâ€™da eÄŸitim yÄ±llarÄ± geniÅŸler, test yÄ±lÄ± 1 yÄ±l ilerler:

Fold	Train YÄ±llarÄ±	Test YÄ±lÄ±
1	2019	2020
2	2019â€“2020	2021
3	2019â€“2021	2022
4	2019â€“2022	2023
5	2019â€“2023	2024

Bu yapÄ± ÅŸu avantajlarÄ± saÄŸlar:

ğŸš« Zero leakage

ğŸ•’ Zaman sÄ±rasÄ± bozulmaz

ğŸ¯ GerÃ§ek dÃ¼nyaya en yakÄ±n validasyon yapÄ±sÄ±
