ğŸŒ GII TimeFold CV Forecast (2021â€“2025)
Zero-Leakage, Time-Aware Machine Learning Forecasting Pipeline

Bu proje, Global Innovation Index (GII) tahmini iÃ§in tasarlanmÄ±ÅŸ, tamamen sÄ±zÄ±ntÄ±sÄ±z, zamana duyarlÄ±, gerÃ§ekÃ§i ve tekrarlanabilir bir makine Ã¶ÄŸrenimi pipelineâ€™Ä±dÄ±r.
Pipeline, yÄ±llar arasÄ± bilgi sÄ±zÄ±ntÄ±sÄ±nÄ± tamamen ortadan kaldÄ±ran Time-Fold Cross-Validation yapÄ±sÄ±nÄ± kullanÄ±r.

ğŸ§­ 1. Proje Ã–zeti

Bu proje, yÄ±llÄ±k veriler Ã¼zerinde gelecek yÄ±llarÄ± tahmin etmek iÃ§in tasarlanmÄ±ÅŸ, tamamen sÄ±zÄ±ntÄ±sÄ±z, gerÃ§ekÃ§i, zaman boyutuna duyarlÄ± bir makine Ã¶ÄŸrenimi pipelineâ€™Ä±dÄ±r.

Pipeline; veri temizleme, Ã¶zellik seÃ§imi, Ã§oklu model eÄŸitimi ve zaman tabanlÄ± Ã§apraz doÄŸrulama adÄ±mlarÄ±nÄ± eksiksiz uygulayarak 2025 tahmini Ã¼retir.

KullanÄ±lan ana bileÅŸenler:

ğŸ›¡ Zero-Leakage Training

â³ Time-Based Fold Cross-Validation (Year â†’ Year+1)

ğŸ” Modified Z-Score Outlier Detection

ğŸ©º Median + KNN Imputation (train-only)

ğŸ“ Train-Only Standardization

ğŸ§¬ LASSO Feature Selection

ğŸ” Iterative VIF Filtering (Multicollinearity)

ğŸ¤– ML Modelleri: XGBoost, LightGBM, RandomForest, AdaBoost

ğŸ¯ Son yÄ±l (2025) iÃ§in final tahmini

ğŸ—‚ï¸ 2. Pipeline Mimarisi

Notebook'un uyguladÄ±ÄŸÄ± adÄ±mlar aÅŸaÄŸÄ±daki gibi Ã¶zetlenmiÅŸtir.

ğŸ” 2.1 Outlier Detection â€” Modified Z-Score

YalnÄ±zca train yÄ±llarÄ±nda hesaplanÄ±r

|Z| > 3.5 olan gÃ¶zlemler â†’ NaN

Median & MAD â†’ leakageâ€™sÄ±z hesaplama

âœ” Test set'e dokunmaz
âœ” Gelecek yÄ±llarÄ±n bilgisi kullanÄ±lmaz

ğŸ©º 2.2 Median Imputation (Only Outlier NaNs)

Outlier â†’ NaN olan deÄŸerleri doldurur

Train median â†’ testâ€™e uygulanÄ±r

Ã‡ifte imputasyon yoktur

ğŸ“ 2.3 Scaling (StandardScaler â€” Train Only)
scaler.fit(train)
scaler.transform(train)
scaler.transform(test)


âœ” Parametreler geleceÄŸi gÃ¶rmez
âœ” Zaman sÄ±rasÄ± korunur

ğŸ§® 2.4 KNN Imputation â€” Scaled Domain

Notebookâ€™taki prensip:

scale â†’ KNN â†’ inverse scale

Train scaled â†’ KNN ile doldurulur

Test scaled â†’ train-fitted KNN ile doldurulur

Sonra inverse-scale edilir

ğŸ§¬ 2.5 LASSO Feature Selection (LassoCV)

CV ile optimum alpha

SÄ±fÄ±r olmayan katsayÄ±lÄ± deÄŸiÅŸkenler

SeÃ§ilmiÅŸ deÄŸiÅŸken tablosu

TÃ¼rkÃ§e Ã§eviri eÅŸlemeleri

ğŸ” 2.6 Multicollinearity Control â€” VIF Filtering

VIF > 10 olan deÄŸiÅŸkenler Ã§Ä±karÄ±lÄ±r

DÃ¶ngÃ¼ VIF < 10 olana kadar devam eder

SonuÃ§: daha stabil, daha anlamlÄ± Ã¶zellik seti
:

ğŸ¤– 3. Model EÄŸitimi

Notebookâ€™ta dÃ¶rt model ile eÄŸitim yapÄ±lÄ±r:

âš¡ XGBoost Regressor

Gradient boosting

YÃ¼ksek doÄŸruluk

HÄ±zlÄ± hesaplama

ğŸ’¡ LightGBM Regressor

BÃ¼yÃ¼k veri iÃ§in optimize

DÃ¼ÅŸÃ¼k gecikme

Memory-efficient

ğŸŒ² RandomForest Regressor

Non-linear iliÅŸkilerde gÃ¼Ã§lÃ¼

YÃ¼ksek stabilite

Bagging tabanlÄ± yapÄ±

ğŸ”º AdaBoost Regressor

(Notebook kodunda DecisionTree tabanlÄ± AdaBoost modeli var)

Weak learner â†’ gÃ¼Ã§lÃ¼ modele dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r

Outlierâ€™lara karÅŸÄ± duyarlÄ±

ZayÄ±f iliÅŸkilerde bile iyileÅŸtirici etki saÄŸlar

Ã–zellikle yÃ¼ksek bias durumlarÄ±nda gÃ¼Ã§lÃ¼ sonuÃ§ verir

Her model iÃ§in ÅŸu metrikler hesaplanÄ±r:

Train RÂ²

Test RÂ²

RMSE

MAE

MAPE (%)

Time-Fold CV RÂ² (Mean & Std)

Model Ã‡alÄ±ÅŸma SÃ¼resi

4. Time-Fold Cross-Validation YapÄ±sÄ±

Her foldâ€™da eÄŸitim yÄ±llarÄ± geniÅŸler, test yÄ±lÄ± 1 yÄ±l ilerler:,
| Fold | Train YÄ±llarÄ± | Test YÄ±lÄ± |
| ---- | ------------- | --------- |
| 1    | 2019          | 2020      |
| 2    | 2019â€“2020     | 2021      |
| 3    | 2019â€“2021     | 2022      |
| 4    | 2019â€“2022     | 2023      |
| 5    | 2019â€“2023     | 2024      |

Bu yapÄ± ÅŸu avantajlarÄ± saÄŸlar:

ğŸš« Zero leakage

ğŸ•’ Zaman sÄ±rasÄ± bozulmaz

ğŸ¯ GerÃ§ek dÃ¼nyaya en yakÄ±n validasyon yapÄ±sÄ±

ğŸ“ˆ 5. Final Tahmin (Forecast) Ãœretimi

Notebook sonunda:

Train dÃ¶nemindeki tÃ¼m yÄ±llar ile model eÄŸitilir

Son yÄ±l (Ã¶rn. 2025) iÃ§in tahmin Ã¼retilir

Ã–rnek Ã§Ä±ktÄ±:

COUNTRY     |  PRED_2025
------------|------------
Country A   |   47.82
Country B   |   61.12
Country C   |   54.30
...
